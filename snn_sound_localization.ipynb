{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mercadoerik1031/snn-sound-localization/blob/new_approach/snn_sound_localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwwANRnDjZcI"
      },
      "source": [
        "#**SNN Sounnd Localization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqx8gNURjTAG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6vcXjzWStl0",
        "outputId": "272cd8e0-3463-491c-c8ad-fb28bf542194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf-z4LGrbj7m"
      },
      "source": [
        "# pip Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1ue5M3A9bSHA",
        "outputId": "4a422f6b-2bcf-442b-f39d-2e95d2411041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install icecream snntorch --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSMYypS0X3wv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D2JtHkLFX47Z"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "\n",
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qXpXNVaSoFq"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OsF-UzANSoFr"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    # Paths\n",
        "    \"metadata_path\": r\"/content/drive/My Drive/Colab Notebooks/Masters Project/metadata.parquet\",\n",
        "    \"ambisonic_path\": r\"/content/drive/My Drive/Colab Notebooks/Masters Project/spatial_librispeech_sample/ambisonics_sample\",\n",
        "    \"noise_path\": r\"/content/drive/My Drive/Colab Notebooks/Masters Project/spatial_librispeech_sample/noise_ambisonics_sample\",\n",
        "\n",
        "    # Device\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "\n",
        "    # Audio Info\n",
        "    \"sr\": 16_000,\n",
        "    \"n_fft\": 256, #512\n",
        "    \"hop_length\": 256,\n",
        "\n",
        "    # SNN\n",
        "    \"num_steps\": 10,\n",
        "    \"thresh1\": 6,\n",
        "    \"thresh2\": 3,\n",
        "    \"thresh3\": 5,\n",
        "    \"beta\": 0.2,\n",
        "\n",
        "    # DataLoader\n",
        "    \"batch_size\": 16,\n",
        "    \"seed\": 42,\n",
        "\n",
        "    # Training\n",
        "    \"epochs\": 5,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxD1mqBjc2Rr"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LbtuY592ICC"
      },
      "source": [
        "## Load Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GRoEdDWwmsl5"
      },
      "outputs": [],
      "source": [
        "def filter_data(\n",
        "    metadata_path=config[\"metadata_path\"],\n",
        "    ambisonics_path=config[\"ambisonic_path\"],\n",
        "    noise_path=config[\"noise_path\"]\n",
        "    ):\n",
        "\n",
        "    metadata = pd.read_parquet(metadata_path, engine=\"pyarrow\")\n",
        "\n",
        "    ambisonic_file_names = [f for f in os.listdir(ambisonics_path) if os.path.isfile(os.path.join(ambisonics_path, f))]\n",
        "    ambisonic_file_names.sort()\n",
        "\n",
        "    noise_file_names = [f for f in os.listdir(noise_path) if os.path.isfile(os.path.join(noise_path, f))]\n",
        "    noise_file_names.sort()\n",
        "\n",
        "    if ambisonic_file_names == noise_file_names:\n",
        "        sample_ids = [int(f.split(\".\")[0].lstrip(\"0\") or 0) for f in ambisonic_file_names]\n",
        "\n",
        "        # Filter metadata to include only rows with sample_ids from available files\n",
        "        metadata = metadata[metadata[\"sample_id\"].isin(sample_ids)]\n",
        "\n",
        "        ambisonic_files = [os.path.join(ambisonics_path, f) for f in ambisonic_file_names]\n",
        "        noise_files = [os.path.join(noise_path, f) for f in noise_file_names]\n",
        "    else:\n",
        "        raise ValueError(\"ambisonic_files and noise_files do not match\")\n",
        "\n",
        "\n",
        "    return metadata, ambisonic_files, noise_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwh3vT0uc36u"
      },
      "source": [
        "## Load and Pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UCSZ3nnKYFyI"
      },
      "outputs": [],
      "source": [
        "def load_and_pad(ambisonic_path, noise_path=None, sr=config[\"sr\"], max_duration=None):\n",
        "    if max_duration is None:\n",
        "        raise ValueError(\"Enter Value or max_duration\")\n",
        "\n",
        "    max_samples = max_duration * sr\n",
        "\n",
        "    ambi_audio, _ = librosa.load(ambisonic_path, sr=sr, mono=False)\n",
        "    ambi_audio = librosa.util.fix_length(ambi_audio, size=max_samples)\n",
        "\n",
        "    if noise_path:\n",
        "        noise_audio, _ = librosa.load(noise_path, sr=sr, mono=False)\n",
        "        noise_audio = librosa.util.fix_length(noise_audio, size=max_samples)\n",
        "        audio = ambi_audio + noise_audio\n",
        "\n",
        "    else:\n",
        "        audio = ambi_audio\n",
        "\n",
        "    return audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89EOIG0tRvc4"
      },
      "source": [
        "## Feature Extraction (STFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zJjdgzjZ2P9V"
      },
      "outputs": [],
      "source": [
        "def stft(audio, n_fft=config[\"n_fft\"], hop_length=config[\"hop_length\"]):\n",
        "    features = []\n",
        "\n",
        "    for i in range(audio.shape[0]):\n",
        "        channel = np.abs(librosa.stft(audio[i, :], n_fft=n_fft, hop_length=hop_length))\n",
        "        features.append(channel)\n",
        "\n",
        "    return np.array(features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY-QWVV5Rze1"
      },
      "source": [
        "## Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v1F0rkT53VSK"
      },
      "outputs": [],
      "source": [
        "def normalize(features):\n",
        "    mean = np.mean(features, axis=0)\n",
        "    std = np.std(features, axis=0)\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    normalized_feat = (features - mean) / (std + epsilon)\n",
        "\n",
        "    return torch.tensor(normalized_feat).float()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlIOEPJGz780"
      },
      "source": [
        "## Split Metadata\n",
        "### Train, Val, Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XXuKphFYkqqp"
      },
      "outputs": [],
      "source": [
        "def split_data(metadata, validation_size=0.2, random_state=42):\n",
        "\n",
        "    # Initialize all rows with 'set' as 'test' based on the existing 'split' column\n",
        "    metadata['set'] = metadata['split']\n",
        "\n",
        "    # Identify indices of rows marked for training\n",
        "    train_indices = metadata[metadata['split'] == 'train'].index\n",
        "\n",
        "    # Split the train_indices into training and validation sets\n",
        "    train_idx, valid_idx = train_test_split(train_indices, test_size=validation_size, random_state=random_state)\n",
        "\n",
        "    # Update the 'set' column to mark validation\n",
        "    metadata.loc[valid_idx, 'set'] = 'validation'\n",
        "\n",
        "    return metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calc Median Absolute Error"
      ],
      "metadata": {
        "id": "NK8KjPuix08Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WCIovPA7AFxl"
      },
      "outputs": [],
      "source": [
        "def calculate_3d_angle_error(true_azimuth, true_elevation, pred_azimuth, pred_elevation):\n",
        "    # Calculate the 3D angle error in radians\n",
        "    angle_error_rad = torch.acos(\n",
        "        torch.sin(true_azimuth) * torch.sin(pred_azimuth) +\n",
        "        torch.cos(true_azimuth) * torch.cos(pred_azimuth) * torch.cos(true_elevation - pred_elevation)\n",
        "    )\n",
        "\n",
        "    # Convert the angle error to degrees for interpretability\n",
        "    angle_error_deg = torch.rad2deg(angle_error_rad)\n",
        "\n",
        "    # Calculate the median absolute error of the angle in degrees\n",
        "    median_abs_error_deg = torch.median(torch.abs(angle_error_deg))\n",
        "\n",
        "    return median_abs_error_deg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urXArOgwz780"
      },
      "source": [
        "# Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "clGVHb3WezqQ"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, metadata, dataset_type, audio_files, noise_files=None, transform=None, sr=config[\"sr\"]):\n",
        "        # Filter metadata for the specified dataset type\n",
        "        self.metadata = metadata\n",
        "        self.dataset_type = dataset_type\n",
        "        self.audio_files = audio_files\n",
        "        self.noise_files = noise_files\n",
        "        self.transform = transform\n",
        "        self.max_duration = int(np.ceil(self.metadata[\"audio_info/duration\"].max()))\n",
        "        self.sr = sr\n",
        "        self.num_steps = config[\"num_steps\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_files[idx]\n",
        "        noise_path = self.noise_files[idx] if self.noise_files else None\n",
        "\n",
        "        # Extract the sample id from the audio file name\n",
        "        sample_id = int(os.path.basename(audio_path).split(\".\")[0].lstrip(\"0\") or 0)\n",
        "\n",
        "        # Attempt to get the corresponding labels from the metadata\n",
        "        label_rows = self.metadata[self.metadata['sample_id'] == sample_id]\n",
        "\n",
        "        if label_rows.empty:\n",
        "            raise ValueError(f\"Sample ID {sample_id} not found in metadata for file {audio_path}\")\n",
        "\n",
        "        labels = label_rows[['speech/azimuth', 'speech/elevation']].values[0]\n",
        "\n",
        "        # Correctly convert labels to a tensor\n",
        "        labels = labels.astype(\"float32\")  # Ensure this conversion is correctly applied\n",
        "        labels_tensor = torch.from_numpy(labels)\n",
        "\n",
        "        # Placeholder for actual audio loading and preprocessing functions\n",
        "        audio = load_and_pad(audio_path, noise_path, max_duration=self.max_duration)\n",
        "        audio = stft(audio)\n",
        "        audio = normalize(audio)\n",
        "        spike_train = spikegen.rate(audio, num_steps=self.num_steps)\n",
        "\n",
        "        if self.transform:\n",
        "            audio = self.transform(audio)\n",
        "\n",
        "        return audio, labels_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI5HDEGUAFxl"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SNN"
      ],
      "metadata": {
        "id": "OSfAe_ExyHob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(SNN, self).__init__()\n",
        "        self.thresh1 = config[\"thresh1\"]\n",
        "        self.thresh2 = config[\"thresh2\"]\n",
        "        self.thresh3 = config[\"thresh3\"]\n",
        "        self.beta = config[\"beta\"]\n",
        "        self.num_steps = config[\"num_steps\"]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=(3, 3))\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.lif1 = snn.Leaky(beta=self.beta, threshold=self.thresh1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.lif2 = snn.Leaky(beta=self.beta, threshold=self.thresh2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3))\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.max_pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.lif3 = snn.Leaky(beta=self.beta, threshold=self.thresh3)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(458752, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, inpt):\n",
        "        #print(f\"Input shape: {inpt.shape}\")  # Print the input shape\n",
        "\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        out_rec = []\n",
        "        mem3_rec = []\n",
        "\n",
        "        for step in range(self.num_steps):\n",
        "            current1 = self.conv1(inpt)\n",
        "            #print(f\"After conv1 shape: {current1.shape}\")\n",
        "            current1 = self.batch_norm1(current1)\n",
        "            current1 = self.max_pool1(current1)\n",
        "            spike1, mem1 = self.lif1(current1, mem1)\n",
        "\n",
        "            current2 = self.conv2(spike1)\n",
        "            #print(f\"After conv2 shape: {current2.shape}\")\n",
        "            current2 = self.batch_norm2(current2)\n",
        "            current2 = self.max_pool2(current2)\n",
        "            spike2, mem2 = self.lif2(current2, mem2)\n",
        "\n",
        "            current3 = self.conv3(spike2)\n",
        "            #print(f\"After conv3 shape: {current3.shape}\")\n",
        "            current3 = self.batch_norm3(current3)\n",
        "            current3 = self.max_pool3(current3)\n",
        "            spike3, mem3 = self.lif3(current3, mem3)\n",
        "\n",
        "            flatten = self.flatten(spike3)\n",
        "            #print(f\"After flatten shape: {flatten.shape}\")\n",
        "\n",
        "            fc = self.fc1(flatten)\n",
        "            #print(f\"After fc1 shape: {fc.shape}\")\n",
        "\n",
        "            out = self.fc2(fc)\n",
        "            #print(f\"Output shape: {out.shape}\")\n",
        "\n",
        "            out_rec.append(out)\n",
        "            mem3_rec.append(mem3)\n",
        "\n",
        "        # Assuming you want to average the outputs over the steps\n",
        "        out_avg = torch.mean(torch.stack(out_rec), dim=0)\n",
        "        #print(f\"Average output shape: {out_avg.shape}\")\n",
        "\n",
        "        return out_avg"
      ],
      "metadata": {
        "id": "aHaziY77SBlu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Function"
      ],
      "metadata": {
        "id": "3K2HFfZhyKK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u2QuxtLqAFxl"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    #print(\"Training\")\n",
        "\n",
        "    train_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "\n",
        "        # ic(outputs)\n",
        "        # ic(labels)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        true_azimuths.append(labels[:, 0].detach())\n",
        "        true_elevations.append(labels[:, 1].detach())\n",
        "        pred_azimuths.append(outputs[:, 0].detach())\n",
        "        pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Function"
      ],
      "metadata": {
        "id": "aGpWOwyIyM4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UFRl1k9lAFxl"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    #print(\"Validation\")\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, labels) in enumerate(val_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            # ic(outputs)\n",
        "            # ic(labels)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "            true_azimuths.append(labels[:, 0].detach())\n",
        "            true_elevations.append(labels[:, 1].detach())\n",
        "            pred_azimuths.append(outputs[:, 0].detach())\n",
        "            pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    valid_loss = valid_loss / len(val_loader.dataset)\n",
        "\n",
        "    return valid_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Function"
      ],
      "metadata": {
        "id": "UgAs0ZJnyO-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U-Oz5P8dAFxl"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, device):\n",
        "    #print(\"Testing\")\n",
        "\n",
        "    test_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, labels) in enumerate(test_loader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            # ic(outputs)\n",
        "            # ic(labels)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * data.size(0)\n",
        "\n",
        "            true_azimuths.append(labels[:, 0].detach())\n",
        "            true_elevations.append(labels[:, 1].detach())\n",
        "            pred_azimuths.append(outputs[:, 0].detach())\n",
        "            pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Code"
      ],
      "metadata": {
        "id": "UNnufl8PyZYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata, ambisonic_files, noise_files = filter_data()\n",
        "metadata = split_data(metadata)\n"
      ],
      "metadata": {
        "id": "ywAEk8Vsx9nu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = config[\"device\"]\n",
        "model = SNN(config).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "t8-rkbp5yAur"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = AudioDataset(metadata, 'train', ambisonic_files, noise_files)\n",
        "val_set = AudioDataset(metadata, \"validation\", ambisonic_files, noise_files)\n",
        "test_set = AudioDataset(metadata, \"test\", ambisonic_files, noise_files)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=config[\"batch_size\"], shuffle=False)"
      ],
      "metadata": {
        "id": "6zDkpEImKBzc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-Dy18OOKAFxl",
        "outputId": "bd5dfa00-b5d7-415e-b661-21298fb89abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| outputs: tensor([[ 0.0130, -0.0351],\n",
            "                     [ 0.0171,  0.0064],\n",
            "                     [ 0.0335, -0.0201],\n",
            "                     [-0.0303,  0.0038],\n",
            "                     [ 0.0254,  0.0103],\n",
            "                     [ 0.0142, -0.0165],\n",
            "                     [ 0.0509,  0.0313],\n",
            "                     [ 0.0288,  0.0133],\n",
            "                     [-0.0281,  0.0025],\n",
            "                     [-0.0254, -0.0250],\n",
            "                     [ 0.0630, -0.0145],\n",
            "                     [ 0.0278,  0.0210],\n",
            "                     [ 0.0105,  0.0141],\n",
            "                     [ 0.0360,  0.0256],\n",
            "                     [ 0.0534, -0.0011],\n",
            "                     [ 0.0176, -0.0043]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[-5.2584e-01, -2.8116e-01],\n",
            "                    [ 1.8784e+00,  1.6417e-01],\n",
            "                    [-1.7161e+00,  3.9511e-02],\n",
            "                    [-2.0596e+00,  1.7430e-03],\n",
            "                    [ 5.3497e-01, -1.3366e-01],\n",
            "                    [-8.9757e-01, -6.4136e-02],\n",
            "                    [ 4.1222e-01,  1.5098e-01],\n",
            "                    [-9.5082e-01, -4.8154e-01],\n",
            "                    [-1.4431e+00, -2.3735e-02],\n",
            "                    [-4.3084e-01,  1.2060e-01],\n",
            "                    [ 2.7526e+00,  7.8001e-02],\n",
            "                    [-2.9328e+00,  3.6498e-02],\n",
            "                    [-2.4435e+00, -2.2619e-01],\n",
            "                    [-2.2861e+00, -5.6479e-02],\n",
            "                    [-1.3532e+00,  3.0860e-01],\n",
            "                    [-1.4758e+00,  5.1140e-01]], device='cuda:0')\n",
            "ic| outputs: tensor([[ -7.2236,   0.5785],\n",
            "                     [-61.3885,   5.3897],\n",
            "                     [-57.1277,   5.4571],\n",
            "                     [-75.1389,   6.8450],\n",
            "                     [-52.8639,   5.6044],\n",
            "                     [-13.2970,   2.0396],\n",
            "                     [-18.3077,   1.5982],\n",
            "                     [-40.6253,   4.2387],\n",
            "                     [-12.2623,   0.9323],\n",
            "                     [-18.8620,   1.6394],\n",
            "                     [-47.9687,   4.9721],\n",
            "                     [-43.8393,   5.1421],\n",
            "                     [-70.2562,   6.0158],\n",
            "                     [ -3.9740,   0.5555],\n",
            "                     [-23.7442,   2.0732],\n",
            "                     [-20.2649,   1.7514]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[ 2.7808,  0.3810],\n",
            "                    [-2.8987, -0.0418],\n",
            "                    [-0.6640, -0.1093],\n",
            "                    [-0.0450,  0.0770],\n",
            "                    [ 1.9736,  0.0332],\n",
            "                    [-0.4049,  0.0478],\n",
            "                    [ 0.6587,  0.0721],\n",
            "                    [-0.7807, -0.1691],\n",
            "                    [ 1.6538,  0.1112],\n",
            "                    [ 0.9411, -0.2826],\n",
            "                    [ 2.9023,  0.0279],\n",
            "                    [-2.5738, -0.0541],\n",
            "                    [ 2.0215, -0.1745],\n",
            "                    [-2.4118,  0.2571],\n",
            "                    [-1.8115, -0.0658],\n",
            "                    [ 1.6889, -0.0206]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 0.1702,  0.0472],\n",
            "                     [-2.8475,  1.7904],\n",
            "                     [-4.3196,  3.0642],\n",
            "                     [-3.6238,  2.6033],\n",
            "                     [ 0.0582,  0.5653],\n",
            "                     [ 0.5289,  0.5756],\n",
            "                     [ 3.0603,  1.1383],\n",
            "                     [ 0.6725,  0.4492],\n",
            "                     [-4.8331,  2.7976],\n",
            "                     [ 0.0932,  0.5649],\n",
            "                     [ 1.6087,  0.4257],\n",
            "                     [-0.9770,  0.6672],\n",
            "                     [-0.3814,  0.7182],\n",
            "                     [-3.4468,  2.0694],\n",
            "                     [ 0.6882,  0.2439],\n",
            "                     [ 0.0761,  0.5805]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[ 2.6811e+00,  3.7963e-02],\n",
            "                    [-2.4682e+00, -3.3624e-02],\n",
            "                    [ 6.1203e-01, -7.6691e-02],\n",
            "                    [-7.8087e-01,  9.9227e-02],\n",
            "                    [-1.3710e+00, -7.2982e-02],\n",
            "                    [-2.9434e+00, -3.4045e-02],\n",
            "                    [ 9.5209e-01, -1.4383e-02],\n",
            "                    [ 7.9827e-01, -3.1655e-02],\n",
            "                    [ 1.8942e-01, -7.3174e-02],\n",
            "                    [-3.0272e+00, -1.7493e-01],\n",
            "                    [ 1.7731e-03, -3.2312e-02],\n",
            "                    [-1.3017e+00, -2.6627e-02],\n",
            "                    [ 1.9847e+00,  3.4765e-01],\n",
            "                    [-2.6678e+00, -4.4233e-02],\n",
            "                    [ 1.6522e+00, -2.8541e-01],\n",
            "                    [-1.2202e-01, -1.1979e-02]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 5.6294e+00, -4.0768e-01],\n",
            "                     [ 1.5117e+01, -7.7099e-01],\n",
            "                     [ 5.4375e+00, -1.0218e-02],\n",
            "                     [ 1.4150e+00,  4.8783e-02],\n",
            "                     [ 9.3661e-01,  3.3809e-02],\n",
            "                     [ 1.0971e+01, -5.4745e-01],\n",
            "                     [ 1.6405e+00, -1.3522e-01],\n",
            "                     [ 9.0182e+00, -2.2223e-01],\n",
            "                     [ 8.2160e-01, -6.7064e-02],\n",
            "                     [ 1.2467e+00, -1.2381e-01],\n",
            "                     [ 2.4347e+01, -1.2626e+00],\n",
            "                     [ 1.8570e+00, -1.1640e-01],\n",
            "                     [ 1.9267e+01, -9.8443e-01],\n",
            "                     [ 2.7372e+01, -1.5006e+00],\n",
            "                     [ 9.7874e+00, -1.1530e-01],\n",
            "                     [ 1.7073e+00, -6.4220e-02]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[ 2.1914,  0.0474],\n",
            "                    [ 1.9062,  0.2093],\n",
            "                    [ 1.2183, -0.1867],\n",
            "                    [ 0.1019, -0.2871],\n",
            "                    [ 0.9400,  0.5403],\n",
            "                    [ 1.6969,  0.0864],\n",
            "                    [ 0.7458, -0.0729],\n",
            "                    [-2.1294,  0.1043],\n",
            "                    [-0.9871, -0.2683],\n",
            "                    [-2.6925,  0.2015],\n",
            "                    [-0.3859, -0.2492],\n",
            "                    [-1.2475, -0.2236],\n",
            "                    [-2.2192, -0.1324],\n",
            "                    [ 0.0394, -0.0195],\n",
            "                    [-0.0725, -0.1099],\n",
            "                    [-0.3119,  0.1940]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 8.6505, -0.8677],\n",
            "                     [ 1.3451, -0.2076],\n",
            "                     [ 6.5749, -0.4726],\n",
            "                     [ 5.4497, -0.8615],\n",
            "                     [10.7311, -1.4711],\n",
            "                     [ 9.4629, -1.2373],\n",
            "                     [ 6.2965, -0.6635],\n",
            "                     [ 5.7791, -0.2665],\n",
            "                     [ 1.6953, -0.1266],\n",
            "                     [ 6.5146, -1.0308],\n",
            "                     [ 1.2603, -0.1174],\n",
            "                     [ 5.2764, -0.6326],\n",
            "                     [ 5.2955, -0.5817],\n",
            "                     [14.1902, -1.6062],\n",
            "                     [ 0.5040, -0.0594],\n",
            "                     [ 8.9962, -1.5471]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[ 2.0317, -0.1045],\n",
            "                    [-1.5859, -0.0634],\n",
            "                    [-1.2704,  0.0521],\n",
            "                    [ 2.1054, -0.1538],\n",
            "                    [-0.3195, -0.0378],\n",
            "                    [-2.5792, -0.1413],\n",
            "                    [ 1.3628,  0.0406],\n",
            "                    [-2.7962, -0.0899],\n",
            "                    [ 1.3956, -0.0505],\n",
            "                    [ 0.4181,  0.3923],\n",
            "                    [ 1.6501, -0.0931],\n",
            "                    [ 0.6366,  0.0988],\n",
            "                    [-0.8381, -0.3093],\n",
            "                    [ 3.0852,  0.2077],\n",
            "                    [-0.2629,  0.2480],\n",
            "                    [ 0.3111,  0.4339]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 6.5128, -1.0542],\n",
            "                     [ 0.8524, -0.1279],\n",
            "                     [ 2.5743, -0.4023],\n",
            "                     [13.1332, -2.3468],\n",
            "                     [ 0.6720, -0.0885],\n",
            "                     [ 0.6023, -0.0816],\n",
            "                     [ 5.6739, -0.9715],\n",
            "                     [ 2.0060, -0.2979],\n",
            "                     [ 5.5695, -0.7707],\n",
            "                     [10.2972, -1.6148],\n",
            "                     [ 7.7969, -1.4752],\n",
            "                     [ 0.4705, -0.0969],\n",
            "                     [ 3.1669, -0.6480],\n",
            "                     [ 8.0542, -0.8406],\n",
            "                     [ 3.8955, -0.5433],\n",
            "                     [ 2.4416, -0.5709]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[ 0.8188,  0.1626],\n",
            "                    [ 0.8771, -0.3149],\n",
            "                    [-0.9703, -0.1088],\n",
            "                    [ 0.9260,  0.0296],\n",
            "                    [ 2.8815, -0.0914],\n",
            "                    [-0.3343, -0.0851],\n",
            "                    [-0.7264, -0.3633],\n",
            "                    [-0.2884,  0.0731],\n",
            "                    [ 0.7063, -0.0140],\n",
            "                    [ 1.8280,  0.0777],\n",
            "                    [ 2.1103,  0.0500],\n",
            "                    [-1.2684, -0.1448],\n",
            "                    [-0.1602,  0.0744],\n",
            "                    [ 0.4635, -0.2756],\n",
            "                    [ 1.9349, -0.1560],\n",
            "                    [-0.2378,  0.1810]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 4.0718e+00, -6.4511e-01],\n",
            "                     [ 2.3635e-01, -4.7611e-02],\n",
            "                     [ 9.9495e-01, -2.1309e-01],\n",
            "                     [ 2.2102e+00, -5.2234e-01],\n",
            "                     [ 3.6804e+00, -9.7634e-01],\n",
            "                     [ 3.4793e-01, -6.4004e-02],\n",
            "                     [ 4.2116e-01, -5.7655e-02],\n",
            "                     [ 2.8081e+00, -4.0448e-01],\n",
            "                     [ 1.2548e+01, -2.5615e+00],\n",
            "                     [ 4.1429e+00, -5.1591e-01],\n",
            "                     [ 1.0687e+00, -2.3857e-01],\n",
            "                     [ 6.2411e-01, -7.5966e-02],\n",
            "                     [ 4.0961e+00, -7.9101e-01],\n",
            "                     [ 1.4706e-01, -9.1880e-03],\n",
            "                     [ 9.0093e+00, -1.8446e+00],\n",
            "                     [ 8.3173e+00, -1.7413e+00]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[-2.7150, -0.0260],\n",
            "                    [ 0.5429,  0.0314],\n",
            "                    [-1.7202,  0.0342],\n",
            "                    [ 0.3610,  0.1878],\n",
            "                    [-1.9942, -0.1113],\n",
            "                    [ 0.7955,  0.0343],\n",
            "                    [-1.1727, -0.0999],\n",
            "                    [-2.4606,  0.1183],\n",
            "                    [ 0.7475, -0.1065],\n",
            "                    [-0.4648,  0.0475],\n",
            "                    [ 1.9495, -0.7431],\n",
            "                    [ 2.5368, -0.1945],\n",
            "                    [-0.8090,  0.0853],\n",
            "                    [ 1.4144, -0.2244],\n",
            "                    [ 2.7750,  0.1197],\n",
            "                    [-1.2107,  0.1295]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 2.8153, -0.5412],\n",
            "                     [ 2.2347, -0.4740],\n",
            "                     [ 2.6486, -0.3671],\n",
            "                     [ 9.3737, -1.8694],\n",
            "                     [ 2.2983, -0.4386],\n",
            "                     [ 2.0649, -0.6392],\n",
            "                     [ 1.4317, -0.2973],\n",
            "                     [ 0.4172, -0.1806],\n",
            "                     [11.7955, -2.6083],\n",
            "                     [ 4.9232, -1.0394],\n",
            "                     [ 2.0799, -0.2995],\n",
            "                     [ 2.1430, -0.6293],\n",
            "                     [ 0.2227, -0.0680],\n",
            "                     [ 3.9864, -0.9776],\n",
            "                     [ 3.8950, -0.4931],\n",
            "                     [ 0.3837, -0.0725]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[-2.3752e+00, -2.2947e-01],\n",
            "                    [-2.2942e+00,  1.3695e-01],\n",
            "                    [ 8.8813e-01, -1.2410e-01],\n",
            "                    [ 1.5652e-01, -7.7752e-03],\n",
            "                    [ 5.5063e-01,  1.0999e-01],\n",
            "                    [ 2.0124e+00, -5.3490e-02],\n",
            "                    [ 2.8781e+00, -1.8737e-01],\n",
            "                    [-1.2736e+00, -1.8745e-01],\n",
            "                    [ 2.1687e+00, -6.0819e-02],\n",
            "                    [-1.1498e-01,  6.1545e-02],\n",
            "                    [ 8.9007e-01,  6.3269e-04],\n",
            "                    [-1.4608e+00,  3.1716e-02],\n",
            "                    [ 1.9215e+00,  1.1447e-01],\n",
            "                    [ 2.9230e-01, -1.5718e-02],\n",
            "                    [ 3.2655e-01, -1.2761e-01],\n",
            "                    [-1.4451e+00, -6.9582e-02]], device='cuda:0')\n",
            "ic| outputs: tensor([[ 1.6088e-01, -1.4192e-02],\n",
            "                     [ 2.6763e+00, -5.3158e-01],\n",
            "                     [ 6.1727e-01, -1.6422e-01],\n",
            "                     [ 3.2984e+00, -4.3989e-01],\n",
            "                     [ 9.3528e+00, -1.9280e+00],\n",
            "                     [ 3.2464e-01, -1.3079e-01],\n",
            "                     [ 6.7289e+00, -1.4292e+00],\n",
            "                     [ 5.7277e-01, -1.6108e-01],\n",
            "                     [ 2.2179e-01, -1.1517e-01],\n",
            "                     [ 1.2591e+00, -2.0651e-01],\n",
            "                     [ 4.5284e+00, -1.0443e+00],\n",
            "                     [ 1.9555e+00, -5.4424e-01],\n",
            "                     [ 7.5549e-01, -8.0108e-02],\n",
            "                     [ 2.6369e+00, -7.1405e-01],\n",
            "                     [ 6.6606e-01, -1.3059e-01],\n",
            "                     [ 1.9948e-01, -4.7992e-03]], device='cuda:0', grad_fn=<MeanBackward1>)\n",
            "ic| labels: tensor([[-0.7846, -0.0298],\n",
            "                    [-1.3058,  0.0855],\n",
            "                    [-0.2806,  0.2074],\n",
            "                    [-0.8973, -0.0575],\n",
            "                    [-0.9368,  0.2046],\n",
            "                    [ 0.6980, -0.0832],\n",
            "                    [-3.0406,  0.3862],\n",
            "                    [-2.6061, -0.4442],\n",
            "                    [-2.3379,  0.2494],\n",
            "                    [-1.3372, -0.0835],\n",
            "                    [-0.2638, -0.0347],\n",
            "                    [ 1.1804,  0.2144],\n",
            "                    [-2.1348,  0.2113],\n",
            "                    [-2.8828,  0.0872],\n",
            "                    [-2.9693,  0.2030],\n",
            "                    [-2.1843, -0.1524]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a6cf83a74043>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{config['epochs']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_true_azimuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_true_elevation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred_azimuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pred_elevation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_true_azimuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_true_elevation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pred_azimuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pred_elevation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-bb0cb3fd80c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-562af91a8bfc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Placeholder for actual audio loading and preprocessing functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8c6fcbd064a9>\u001b[0m in \u001b[0;36mload_and_pad\u001b[0;34m(ambisonic_path, noise_path, sr, max_duration)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnoise_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnoise_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnoise_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mambi_audio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Otherwise try soundfile first, and then fall back if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFileRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
        "\n",
        "    train_epoch_loss, train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation = train(model, train_loader, criterion, optimizer, device)\n",
        "    valid_epoch_loss, valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "\n",
        "    train_angle_error = calculate_3d_angle_error(train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation)\n",
        "    valid_angle_error = calculate_3d_angle_error(valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation)\n",
        "\n",
        "    print(f\"Train Loss: {train_epoch_loss:.4f} | Validation Loss: {valid_epoch_loss:.4f}\")\n",
        "    print(f\"Train Angle Error: {train_angle_error:.4f} | Validation Angle Error: {valid_angle_error:.4f}\\n\")\n",
        "\n",
        "test_loss, test_true_azimuth, test_true_elevation, test_pred_azimuth, test_pred_elevation = test(model, test_loader, criterion, device)\n",
        "test_angle_error = calculate_3d_angle_error(test_true_azimuth, test_true_elevation, test_pred_azimuth, train_pred_elevation)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Angle Error: {test_angle_error:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3vmT8wWmkV1"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUCDa6CFaZ29"
      },
      "outputs": [],
      "source": [
        "# W = audio[0]\n",
        "# X = audio[1]\n",
        "# Y = audio[2]\n",
        "# Z = audio[3]\n",
        "\n",
        "# W_n = audio_n[0]\n",
        "# Y_n = audio_n[2]\n",
        "# X_n = audio_n[1]\n",
        "# Z_n = audio_n[3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U6m95pUcuLZ"
      },
      "outputs": [],
      "source": [
        "# # Plot each channel\n",
        "# fig, axs = plt.subplots(8, 1, figsize=(10, 8), sharex=True)\n",
        "\n",
        "# axs[0].plot(W)\n",
        "# axs[0].set_title('W Channel')\n",
        "# axs[1].plot(W_n)\n",
        "# axs[1].set_title('W_n Channel')\n",
        "\n",
        "# axs[2].plot(X)\n",
        "# axs[2].set_title('X Channel')\n",
        "# axs[3].plot(X_n)\n",
        "# axs[3].set_title('X_n Channel')\n",
        "\n",
        "\n",
        "# axs[4].plot(Y)\n",
        "# axs[4].set_title('Y Channel')\n",
        "# axs[5].plot(Y_n)\n",
        "# axs[5].set_title('Y_n Channel')\n",
        "\n",
        "# axs[6].plot(Z)\n",
        "# axs[6].set_title('Z Channel')\n",
        "# axs[7].plot(Z_n)\n",
        "# axs[7].set_title('Z_n Channel')\n",
        "\n",
        "# # Common settings for all subplots\n",
        "# for ax in axs:\n",
        "#     ax.set_ylabel('Amplitude')\n",
        "#     ax.label_outer()\n",
        "\n",
        "# axs[-1].set_xlabel('Sample')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "R3vmT8wWmkV1"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}