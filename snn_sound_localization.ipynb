{"cells":[{"cell_type":"markdown","metadata":{"id":"EwwANRnDjZcI"},"source":["#**SNN Sounnd Localization**"]},{"cell_type":"markdown","metadata":{"id":"Sqx8gNURjTAG"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":798,"status":"ok","timestamp":1708573341446,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"},"user_tz":480},"id":"K6vcXjzWStl0","outputId":"6f039570-817a-4f2b-b7f8-783678a24b4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"markdown","metadata":{"id":"lf-z4LGrbj7m"},"source":["# pip Installs"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1ue5M3A9bSHA","executionInfo":{"status":"ok","timestamp":1708573346762,"user_tz":480,"elapsed":5318,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["! pip install icecream optuna snntorch --quiet"]},{"cell_type":"markdown","metadata":{"id":"RSMYypS0X3wv"},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"D2JtHkLFX47Z","executionInfo":{"status":"ok","timestamp":1708573349867,"user_tz":480,"elapsed":3114,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["import librosa\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","\n","import os\n","\n","import torch\n","import torchaudio\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","\n","import snntorch as snn\n","from snntorch import spikegen\n","\n","from icecream import ic\n","\n","import optuna\n","\n","import time"]},{"cell_type":"markdown","metadata":{"id":"2qXpXNVaSoFq"},"source":["# Config"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OsF-UzANSoFr","executionInfo":{"status":"ok","timestamp":1708573349867,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["config = {\n","    # Paths\n","    \"metadata_path\": r\"/content/drive/My Drive/Colab Notebooks/sound_localization/data/metadata.parquet\",\n","    \"ambisonic_path\": r\"/content/drive/My Drive/Colab Notebooks/sound_localization/data/ambisonics_lite\",\n","    \"noise_path\": r\"/content/drive/My Drive/Colab Notebooks/sound_localization/data/noise_ambisonics_lite\",\n","\n","    # Device\n","    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","\n","    # Audio Info\n","    \"sr\": 16_000,\n","    \"n_fft\": 512,\n","    \"hop_length\": 512, # 256\n","\n","    # SNN\n","    \"num_steps\": 12,\n","    \"thresh1\": 17.175347400305153,\n","    \"thresh2\": 8.12828030444371,\n","    \"thresh3\": 15.5855582787769,\n","    \"beta\": 0.6210988248097677,\n","\n","    # DataLoader\n","    \"batch_size\": 32,\n","\n","    \"seed\": 42,\n","\n","    # Training\n","    \"epochs\": 50, # Apple -> 20\n","    \"lr\": 0.000358787335187998,\n","    \"dropout\": 0.000358787335187998,\n","}"]},{"cell_type":"markdown","metadata":{"id":"nxD1mqBjc2Rr"},"source":["# Preprocess"]},{"cell_type":"markdown","metadata":{"id":"_LbtuY592ICC"},"source":["## Load Metadata"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GRoEdDWwmsl5","executionInfo":{"status":"ok","timestamp":1708573349867,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def filter_data(\n","    metadata_path=config[\"metadata_path\"],\n","    ambisonic_path=config[\"ambisonic_path\"],\n","    noise_path=config[\"noise_path\"],\n","    lite_version=True\n","):\n","\n","    # Check for missing files\n","    metadata = pd.read_parquet(metadata_path)\n","\n","    if lite_version:\n","      metadata = metadata[metadata[\"lite_version\"] == True]\n","\n","    metadata_ids = set(metadata[\"sample_id\"])\n","\n","    # Expected files names\n","    expected_ambi_files = {f\"{id:06}.flac\" for id in metadata_ids}\n","    expected_noise_files = {f\"{id:06}.flac\" for id in metadata_ids}\n","\n","    # Actual File Names\n","    actual_ambi_files = set(os.listdir(ambisonic_path))\n","    actual_noise_files = set(os.listdir(noise_path))\n","\n","    # Check for missing files\n","    missing_ambi_files = expected_ambi_files - actual_ambi_files\n","    missing_noise_files = expected_noise_files - actual_noise_files\n","\n","    # Handle missing files\n","    if missing_ambi_files or missing_noise_files:\n","      raise ValueError(f\"Missing Files: {missing_ambi_files} {missing_noise_files}\")\n","\n","    # List of ambisonic and noise file paths\n","    ambi_files = [os.path.join(ambisonic_path, f) for f in expected_ambi_files]\n","    noise_files = [os.path.join(noise_path, f) for f in expected_noise_files]\n","\n","    return metadata, ambi_files, noise_files"]},{"cell_type":"markdown","metadata":{"id":"Uwh3vT0uc36u"},"source":["## Load and Pad"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UCSZ3nnKYFyI","executionInfo":{"status":"ok","timestamp":1708573349867,"user_tz":480,"elapsed":3,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def load_and_pad(ambisonic_path, noise_path=None, sr=config[\"sr\"], max_duration=None):\n","    if max_duration is None:\n","        raise ValueError(\"Enter Value or max_duration\")\n","\n","    max_samples = max_duration * sr\n","\n","    ambi_audio, _ = librosa.load(ambisonic_path, sr=sr, mono=False)\n","    ambi_audio = librosa.util.fix_length(ambi_audio, size=max_samples)\n","\n","    if noise_path:\n","        noise_audio, _ = librosa.load(noise_path, sr=sr, mono=False)\n","        noise_audio = librosa.util.fix_length(noise_audio, size=max_samples)\n","        audio = ambi_audio + noise_audio\n","\n","    else:\n","        audio = ambi_audio\n","\n","    return audio"]},{"cell_type":"markdown","metadata":{"id":"89EOIG0tRvc4"},"source":["## Feature Extraction (STFT)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zJjdgzjZ2P9V","executionInfo":{"status":"ok","timestamp":1708573349867,"user_tz":480,"elapsed":3,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def stft(audio, n_fft=config[\"n_fft\"], hop_length=config[\"hop_length\"]):\n","    features = []\n","\n","    for i in range(audio.shape[0]):\n","        channel = np.abs(librosa.stft(audio[i, :], n_fft=n_fft, hop_length=hop_length))\n","        features.append(channel)\n","\n","    return np.array(features)\n"]},{"cell_type":"markdown","metadata":{"id":"ZY-QWVV5Rze1"},"source":["## Normalize"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"v1F0rkT53VSK","executionInfo":{"status":"ok","timestamp":1708573350080,"user_tz":480,"elapsed":216,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def normalize(features):\n","    mean = np.mean(features, axis=0)\n","    std = np.std(features, axis=0)\n","    epsilon = 1e-10\n","\n","    normalized_feat = (features - mean) / (std + epsilon)\n","\n","    return torch.tensor(normalized_feat).float()\n"]},{"cell_type":"markdown","metadata":{"id":"XlIOEPJGz780"},"source":["## Split Metadata\n","### Train, Val, Test Split"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XXuKphFYkqqp","executionInfo":{"status":"ok","timestamp":1708573350080,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def split_data(metadata, validation_size=0.2, random_state=42):\n","    metadata['set'] = metadata['split']\n","\n","    # Identify indices of rows marked for training\n","    train_indices = metadata[metadata['split'] == 'train'].index\n","\n","    # Split the train_indices into training and validation sets\n","    train_idx, valid_idx = train_test_split(train_indices, test_size=validation_size, random_state=random_state)\n","\n","    # Update the 'set' column to mark validation\n","    metadata.loc[valid_idx, 'set'] = 'validation'\n","\n","    return metadata"]},{"cell_type":"markdown","metadata":{"id":"NK8KjPuix08Y"},"source":["## Calc Median Absolute Error"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WCIovPA7AFxl","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def calculate_3d_angle_error(true_azimuth, true_elevation, pred_azimuth, pred_elevation):\n","    # Calculate the 3D angle error in radians\n","    angle_error_rad = torch.acos(\n","        torch.sin(true_azimuth) * torch.sin(pred_azimuth) +\n","        torch.cos(true_azimuth) * torch.cos(pred_azimuth) * torch.cos(true_elevation - pred_elevation)\n","    )\n","\n","    # Convert the angle error to degrees for interpretability\n","    angle_error_deg = torch.rad2deg(angle_error_rad)\n","\n","    # Calculate the median absolute error of the angle in degrees\n","    median_abs_error_deg = torch.median(torch.abs(angle_error_deg))\n","\n","    return median_abs_error_deg\n"]},{"cell_type":"markdown","metadata":{"id":"urXArOgwz780"},"source":["# Custom Dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"clGVHb3WezqQ","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["class AudioDataset(Dataset):\n","    def __init__(self, metadata, dataset_type, audio_files, noise_files=None, transform=None, sr=config[\"sr\"]):\n","        self.metadata = metadata\n","        self.dataset_type = dataset_type\n","        self.audio_files = audio_files\n","        self.noise_files = noise_files\n","        self.transform = transform\n","        self.max_duration = int(np.ceil(self.metadata[\"audio_info/duration\"].mean() + metadata[\"audio_info/duration\"].std()))\n","        self.sr = sr\n","        self.num_steps = config[\"num_steps\"]\n","\n","    def __len__(self):\n","        return len(self.audio_files)\n","\n","    def __getitem__(self, idx):\n","        audio_path = self.audio_files[idx]\n","        noise_path = self.noise_files[idx] if self.noise_files else None\n","\n","        # Extract the sample id from the audio file name\n","        sample_id = int(os.path.basename(audio_path).split(\".\")[0].lstrip(\"0\") or 0)\n","\n","        # Attempt to get the corresponding labels from the metadata\n","        label_rows = self.metadata[self.metadata['sample_id'] == sample_id]\n","\n","        if label_rows.empty:\n","            raise ValueError(f\"Sample ID {sample_id} not found in metadata for file {audio_path}\")\n","\n","        labels = label_rows[['speech/azimuth', 'speech/elevation']].values[0]\n","\n","        # labels to a tensor\n","        labels = labels.astype(\"float32\")  # Ensure this conversion is correctly applied\n","        labels_tensor = torch.from_numpy(labels)\n","\n","        # audio loading and preprocessing functions\n","        audio = load_and_pad(audio_path, noise_path, max_duration=self.max_duration)\n","        audio = stft(audio)\n","        audio = normalize(audio)\n","        spike_train = spikegen.rate(audio, num_steps=self.num_steps)\n","\n","        return spike_train, labels_tensor"]},{"cell_type":"markdown","metadata":{"id":"xI5HDEGUAFxl"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"OSfAe_ExyHob"},"source":["## SNN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"iEVAJJcgfwxM","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["class SNN(nn.Module):\n","    def __init__(self, config):\n","        super(SNN, self).__init__()\n","        self.thresh1 = config[\"thresh1\"]\n","        self.thresh2 = config[\"thresh2\"]\n","        self.thresh3 = config[\"thresh3\"]\n","        self.beta = config[\"beta\"]\n","        self.num_steps = config[\"num_steps\"]\n","        self.dropout_prob = config[\"dropout\"]\n","\n","        self.conv1 = nn.Conv2d(4, 32, kernel_size=(3, 3))\n","        self.batch_norm1 = nn.BatchNorm2d(32)\n","        self.max_pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n","        self.lif1 = snn.Leaky(beta=self.beta, threshold=self.thresh1)\n","\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n","        self.batch_norm2 = nn.BatchNorm2d(64)\n","        self.max_pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n","        self.lif2 = snn.Leaky(beta=self.beta, threshold=self.thresh2)\n","\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3))\n","        self.batch_norm3 = nn.BatchNorm2d(128)\n","        self.max_pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n","        self.lif3 = snn.Leaky(beta=self.beta, threshold=self.thresh3)\n","\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(215040, 256)\n","        self.dropout_layer = nn.Dropout(self.dropout_prob)\n","        self.fc2 = nn.Linear(256, 2)\n","\n","    def forward(self, inpt):\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        mem3 = self.lif3.init_leaky()\n","\n","        out_rec = []\n","        mem3_rec = []\n","\n","        inpt = inpt.permute(1, 0, 2, 3, 4) # [num_step, batch_size, channels, width, height]\n","\n","        # ic(inpt.shape)\n","\n","        for step in range(inpt.size(0)):\n","            # ic(inpt[step].shape)\n","\n","            current1 = self.conv1(inpt[step])\n","            current1 = self.batch_norm1(current1)\n","            current1 = self.max_pool1(current1)\n","            spike1, mem1 = self.lif1(current1, mem1)\n","\n","            current2 = self.conv2(spike1)\n","            current2 = self.batch_norm2(current2)\n","            current2 = self.max_pool2(current2)\n","            spike2, mem2 = self.lif2(current2, mem2)\n","\n","            current3 = self.conv3(spike2)\n","            current3 = self.batch_norm3(current3)\n","            current3 = self.max_pool3(current3)\n","            spike3, mem3 = self.lif3(current3, mem3)\n","\n","            flatten = self.flatten(spike3)\n","\n","            fc = self.fc1(flatten)\n","            fc = self.dropout_layer(fc)\n","\n","            out = self.fc2(fc)\n","\n","            out_rec.append(out)\n","            mem3_rec.append(mem3)\n","\n","        # Average the outputs over the steps\n","        out_avg = torch.mean(torch.stack(out_rec), dim=0)\n","\n","        return out_avg\n"]},{"cell_type":"markdown","metadata":{"id":"3K2HFfZhyKK9"},"source":["## Train Function"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"u2QuxtLqAFxl","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def train(model, train_loader, criterion, optimizer, device):\n","    #print(\"Training\")\n","\n","    train_loss = 0.0\n","    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n","\n","    model.train()\n","\n","    for batch_idx, (data, labels) in enumerate(train_loader):\n","        print(f\"Batch {batch_idx+1}/{len(test_loader)}\")\n","\n","        data, labels = data.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","\n","        # ic(outputs)\n","        # ic(labels)\n","\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * data.size(0)\n","\n","        true_azimuths.append(labels[:, 0].detach())\n","        true_elevations.append(labels[:, 1].detach())\n","        pred_azimuths.append(outputs[:, 0].detach())\n","        pred_elevations.append(outputs[:, 1].detach())\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","\n","    return train_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"]},{"cell_type":"markdown","metadata":{"id":"aGpWOwyIyM4C"},"source":["## Validation Function"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"UFRl1k9lAFxl","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def validate(model, val_loader, criterion, device):\n","    #print(\"Validation\")\n","\n","    valid_loss = 0.0\n","    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, labels) in enumerate(val_loader):\n","            print(f\"Batch {batch_idx+1}/{len(test_loader)}\")\n","            data, labels = data.to(device), labels.to(device)\n","\n","            outputs = model(data)\n","\n","            # ic(outputs)\n","            # ic(labels)\n","\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * data.size(0)\n","\n","            true_azimuths.append(labels[:, 0].detach())\n","            true_elevations.append(labels[:, 1].detach())\n","            pred_azimuths.append(outputs[:, 0].detach())\n","            pred_elevations.append(outputs[:, 1].detach())\n","\n","    valid_loss = valid_loss / len(val_loader.dataset)\n","\n","    return valid_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"]},{"cell_type":"markdown","metadata":{"id":"UgAs0ZJnyO-6"},"source":["## Test Function"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U-Oz5P8dAFxl","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["def test(model, test_loader, criterion, device):\n","    #print(\"Testing\")\n","\n","    test_loss = 0.0\n","    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, labels) in enumerate(test_loader):\n","            data, labels = data.to(device), labels.to(device)\n","\n","            outputs = model(data)\n","\n","            # ic(outputs)\n","            # ic(labels)\n","\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item() * data.size(0)\n","\n","            true_azimuths.append(labels[:, 0].detach())\n","            true_elevations.append(labels[:, 1].detach())\n","            pred_azimuths.append(outputs[:, 0].detach())\n","            pred_elevations.append(outputs[:, 1].detach())\n","\n","    test_loss = test_loss / len(test_loader.dataset)\n","\n","    return test_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)"]},{"cell_type":"markdown","metadata":{"id":"UNnufl8PyZYv"},"source":["# Run Code"]},{"cell_type":"code","source":["# from concurrent.futures import ProcessPoolExecutor, as_completed\n","# import functools"],"metadata":{"id":"pW3908C5mPTW","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# def filter_and_split_data():\n","#     # Assuming filter_data() can be run independently and its results\n","#     # are used by split_data().\n","#     metadata, ambisonic_files, noise_files = filter_data()\n","#     metadata = split_data(metadata)\n","#     return metadata, ambisonic_files, noise_files\n","\n","# num_workers = 10\n","\n","# with ProcessPoolExecutor(max_workers=num_workers) as executor:\n","#     future_to_task = {executor.submit(filter_and_split_data): 'Task 1'}\n","#     for future in as_completed(future_to_task):\n","#         try:\n","#             result = future.result()\n","#             # Process your result here\n","#             print(f\"Result: {result}\")\n","#         except Exception as exc:\n","#             print(f\"Generated an exception: {exc}\")"],"metadata":{"id":"nOlGw1yxk9IY","executionInfo":{"status":"ok","timestamp":1708573350081,"user_tz":480,"elapsed":4,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ywAEk8Vsx9nu","executionInfo":{"status":"ok","timestamp":1708573353043,"user_tz":480,"elapsed":2966,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["metadata, ambisonic_files, noise_files = filter_data()\n","metadata = split_data(metadata)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"t8-rkbp5yAur","executionInfo":{"status":"ok","timestamp":1708573354839,"user_tz":480,"elapsed":1799,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["device = config[\"device\"]\n","model = SNN(config).to(device)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"6zDkpEImKBzc","executionInfo":{"status":"ok","timestamp":1708573354839,"user_tz":480,"elapsed":3,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["train_set = AudioDataset(metadata, 'train', ambisonic_files, noise_files)\n","val_set = AudioDataset(metadata, \"validation\", ambisonic_files, noise_files)\n","test_set = AudioDataset(metadata, \"test\", ambisonic_files, noise_files)\n","\n","train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=config[\"batch_size\"], shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=config[\"batch_size\"], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Dy18OOKAFxl"},"outputs":[],"source":["train_loss = []\n","valid_loss = []\n","\n","for epoch in range(config[\"epochs\"]):\n","    print(f\"Epoch {epoch+1}/{config['epochs']}\")\n","\n","    train_epoch_loss, train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation = train(model, train_loader, criterion, optimizer, device)\n","    valid_epoch_loss, valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation = validate(model, val_loader, criterion, device)\n","\n","    train_loss.append(train_epoch_loss)\n","    valid_loss.append(valid_epoch_loss)\n","\n","    train_angle_error = calculate_3d_angle_error(train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation)\n","    valid_angle_error = calculate_3d_angle_error(valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation)\n","\n","    print(f\"Train Loss: {train_epoch_loss:.4f} | Validation Loss: {valid_epoch_loss:.4f}\")\n","    print(f\"Train Angle Error: {train_angle_error:.4f}° | Validation Angle Error: {valid_angle_error:.4f}°\\n\")\n","\n","test_loss, test_true_azimuth, test_true_elevation, test_pred_azimuth, test_pred_elevation = test(model, test_loader, criterion, device)\n","test_angle_error = calculate_3d_angle_error(test_true_azimuth, test_true_elevation, test_pred_azimuth, train_pred_elevation)\n","\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Angle Error: {test_angle_error:.4f}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"BPG6JQW3poqB"},"source":["# Hyper Param Sweep (Optuna)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaSnZMh9o42p","executionInfo":{"status":"aborted","timestamp":1708578623064,"user_tz":480,"elapsed":5,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["# def objective(trial):\n","#     # Hyperparameters to optimize\n","#     config[\"thresh1\"] = trial.suggest_float(\"thresh1\", 1, 30)\n","#     config[\"thresh2\"] = trial.suggest_float(\"thresh2\", 1, 30)\n","#     config[\"thresh3\"] = trial.suggest_float(\"thresh3\", 1, 30)\n","#     config[\"beta\"] = trial.suggest_float(\"beta\", 0.1, 0.9)\n","#     config[\"lr\"] = trial.suggest_float(\"lr\", 1e-10, 1e-3)\n","#     config[\"dropout\"] = trial.suggest_float(\"droput\", 0, 0.8)\n","#     config[\"num_steps\"] = trial.suggest_int(\"num_steps\", 5, 30)\n","\n","#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#     model = SNN(config).to(device)\n","#     criterion = nn.MSELoss()\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n","\n","#     # Data loading code here\n","#     # Assuming train_loader and val_loader are defined\n","\n","#     for epoch in range(config[\"epochs\"]):\n","#         train(model, train_loader, criterion, optimizer, device)\n","#         valid_epoch_loss, valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation = validate(model, val_loader, criterion, device)\n","#         valid_angle_error = calculate_3d_angle_error(valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation)\n","\n","#     return valid_angle_error.item()  # Optuna minimizes this value\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--fHwZNipMmz","executionInfo":{"status":"aborted","timestamp":1708578623064,"user_tz":480,"elapsed":5,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["# def run_study():\n","#     study_name = \"snn_study\"\n","#     storage_name = \"sqlite:///{}.db\".format(study_name)\n","\n","#     study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, direction=\"minimize\")\n","#     study.optimize(objective, n_trials=100)\n","\n","#     # Save the study to disk\n","#     study.trials_dataframe().to_csv(\"study_results.csv\")\n","\n","#     print(\"Study statistics: \")\n","#     print(\"  Number of finished trials: \", len(study.trials))\n","#     print(\"  Best trial:\")\n","#     trial = study.best_trial\n","#     print(\"    Value: \", trial.value)\n","#     print(\"    Params: \")\n","#     for key, value in trial.params.items():\n","#         print(f\"      {key}: {value}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyXVrvX-pODT","executionInfo":{"status":"aborted","timestamp":1708578623064,"user_tz":480,"elapsed":5,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":["# run_study()"]},{"cell_type":"markdown","metadata":{"id":"_sukkW0wznZx"},"source":["[I 2024-02-12 23:15:10,615] Trial 1 finished with value: 33.963905334472656 and parameters: {'thresh1': 17.175347400305153, 'thresh2': 8.12828030444371, 'thresh3': 15.5855582787769, 'beta': 0.6210988248097677, 'lr': 0.000358787335187998, 'droput': 0.7449582513653029}. Best is trial 1 with value: 33.963905334472656."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I6dvFoUMzooQ","executionInfo":{"status":"aborted","timestamp":1708578623064,"user_tz":480,"elapsed":5,"user":{"displayName":"Erik Mercado","userId":"08255589426380637656"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"https://github.com/mercadoerik1031/snn-sound-localization/blob/new_approach/snn_sound_localization.ipynb","timestamp":1707330653413}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}