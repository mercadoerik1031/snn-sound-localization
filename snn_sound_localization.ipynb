{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv4a0CNLlp9v",
        "outputId": "d932c0ab-c1b5-49e7-c83c-5448b59bcf05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install snntorch optuna --quiet"
      ],
      "metadata": {
        "id": "WEtZkfPXl5U5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WRIc1Xhlkxz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ogIzFacrhYZD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from snntorch import utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import optuna\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30LNpXtYlkx8"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nXnOrdx29edp"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    # Filter Data\n",
        "    \"metadata_path\": \"/content/drive/My Drive/Colab Notebooks/Masters Project/data/metadata.parquet\",\n",
        "    \"speech_path\": \"/content/drive/My Drive/Colab Notebooks/Masters Project/data/ambisonics_lite\",\n",
        "    \"noise_path\": \"/content/drive/My Drive/Colab Notebooks/Masters Project/data/noise_ambisonics_lite\",\n",
        "    \"is_lite_version\": True,\n",
        "\n",
        "    # Load Mix and STFT Audio\n",
        "    \"sr\": 16_000,\n",
        "    \"duration\": 0.5,\n",
        "    \"noise_ratio\": None, # Optional (Large #s make noise louder, Small #s make noise quieter)\n",
        "    \"n_fft\": 512,\n",
        "    \"hop_length\": 128,\n",
        "    \"win_length\": 512,\n",
        "\n",
        "    # Split Data\n",
        "    \"val_size\": 0.1,\n",
        "\n",
        "    # Dataset\n",
        "    \"num_steps\": 10,\n",
        "    \"batch_size\": 128,\n",
        "\n",
        "    # SNN\n",
        "    \"do\": 0.6,\n",
        "    \"beta\": 0.65,\n",
        "    \"beta_re\": 0.65,\n",
        "    \"beta_out\": 0.65,\n",
        "        # Active Branch\n",
        "    \"a_thresh1\": 10, \"a_thresh2\": 10, \"a_thresh3\": 10, \"a_thresh4\": 10,\n",
        "        # Reactive Branch\n",
        "    \"re_thresh1\": 10, \"re_thresh2\": 10, \"re_thresh3\": 10, \"re_thresh4\": 10,\n",
        "        # Output Layer\n",
        "    \"out_thresh1\": 10, \"out_thresh2\": 10,\n",
        "\n",
        "    # Training\n",
        "    \"num_epochs\": 80,\n",
        "    \"device\": torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    \"lr\": 0.0003,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ARGPGn_lkx9"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iohwMBylkx-"
      },
      "source": [
        "### Filter Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T-yb90H8ry_W"
      },
      "outputs": [],
      "source": [
        "def filter_data(\n",
        "        metadata_pth=config[\"metadata_path\"],\n",
        "        speech_pth=config[\"speech_path\"],\n",
        "        noise_pth=config[\"noise_path\"],\n",
        "        lite_version=config[\"is_lite_version\"]\n",
        "):\n",
        "\n",
        "    metadata = pd.read_parquet(metadata_pth, engine=\"pyarrow\")\n",
        "    if lite_version:\n",
        "        metadata = metadata[metadata[\"lite_version\"] == True]\n",
        "\n",
        "    data = []\n",
        "    for _, row in metadata.iterrows():\n",
        "        sample = {\n",
        "            \"sample_id\": row[\"sample_id\"],\n",
        "            \"speech_path\": os.path.join(speech_pth, f\"{row['sample_id']:06}.flac\"),\n",
        "            \"noise_path\": os.path.join(noise_pth, f\"{row['sample_id']:06}.flac\") if noise_pth else None,\n",
        "            \"azimuth\": row[\"speech/azimuth\"],\n",
        "            \"elevation\": row[\"speech/elevation\"],\n",
        "            \"split\": row[\"split\"]\n",
        "        }\n",
        "        data.append(sample)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVnpMtoVlkx_"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KzoFwpF4WMFP"
      },
      "outputs": [],
      "source": [
        "def split_data(data, val_size=config[\"val_size\"]):\n",
        "    train_data = [sample for sample in data if sample[\"split\"] == \"train\"]\n",
        "    test_data = [sample for sample in data if sample[\"split\"] == \"test\"]\n",
        "\n",
        "    train_data, val_data = train_test_split(train_data, test_size=val_size, random_state=42)\n",
        "\n",
        "    return train_data, val_data, test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jnohWaFlkyA"
      },
      "source": [
        "### Load, Trim/Pad, STFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gKUl7kz-uRUU"
      },
      "outputs": [],
      "source": [
        "def load_mix_and_stft_foa_audio(\n",
        "        speech_pth,\n",
        "        noise_pth=None,\n",
        "        sr=config[\"sr\"],\n",
        "        duration=config[\"duration\"],\n",
        "        noise_ratio=config[\"noise_ratio\"],\n",
        "        n_fft=config[\"n_fft\"],\n",
        "        hop_length=config[\"hop_length\"],\n",
        "        win_length=config[\"win_length\"],\n",
        "        device=config[\"device\"]\n",
        "):\n",
        "\n",
        "    def preprocess_audio(audio_pth, sr, target_len, device):\n",
        "        num_frames = target_len\n",
        "        audio, audio_sr = torchaudio.load(audio_pth, frame_offset=0, num_frames=num_frames)\n",
        "        audio = audio.to(device)  # Move to GPU\n",
        "        if audio_sr != sr:\n",
        "            resample_transform = torchaudio.transforms.Resample(orig_freq=audio_sr, new_freq=sr)\n",
        "            audio = resample_transform(audio)\n",
        "        max_val = audio.abs().max()\n",
        "        if max_val > 0:  # Avoid division by zero\n",
        "            audio = audio / max_val\n",
        "        # Check if padding is necessary (after resampling, the actual number of samples might change)\n",
        "        actual_len = audio.size(1)\n",
        "        if actual_len < target_len:\n",
        "            padding_size = target_len - actual_len\n",
        "            audio = torch.nn.functional.pad(audio, (0, padding_size), \"constant\", 0)\n",
        "        return audio\n",
        "\n",
        "    device = device\n",
        "    target_len = int(duration * sr)\n",
        "    speech_audio = preprocess_audio(speech_pth, sr, target_len, device)\n",
        "    should_renormalize = False\n",
        "\n",
        "    if noise_pth is not None:\n",
        "        noise_audio = preprocess_audio(noise_pth, sr, target_len, device)\n",
        "\n",
        "        if noise_ratio is not None:\n",
        "            # Adjust noise level relative to speech\n",
        "            noise_audio = noise_audio * noise_ratio\n",
        "            should_renormalize = True\n",
        "\n",
        "        # Mix speech and noise\n",
        "        mixed_audio = speech_audio + noise_audio\n",
        "    else:\n",
        "        mixed_audio = speech_audio\n",
        "\n",
        "    if should_renormalize:\n",
        "        # Re-normalize only if noise has been adjusted and mixed\n",
        "        max_val = mixed_audio.abs().max()\n",
        "        if max_val > 0:\n",
        "            mixed_audio = mixed_audio / max_val\n",
        "\n",
        "    # Move Window to device\n",
        "    window = torch.hann_window(win_length).to(device)\n",
        "\n",
        "    # Compute the STFT of the mixed audio\n",
        "    stft = torch.stft(mixed_audio,\n",
        "                      n_fft=n_fft,\n",
        "                      hop_length=hop_length,\n",
        "                      win_length=win_length,\n",
        "                      window=window,\n",
        "                      center=True,\n",
        "                      normalized=True,\n",
        "                      onesided=False,\n",
        "                      return_complex=True)\n",
        "\n",
        "    return stft\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFP_lrLQlkyA"
      },
      "source": [
        "### Calculate Active and Reactive Intensity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aMt7lTRd_lUw"
      },
      "outputs": [],
      "source": [
        "# def compute_active_reactive_intensities(stft, rho=1.21, c=343):\n",
        "#     \"\"\"\n",
        "#     Compute active and reactive intensity vectors from STFT of 4-channel FOA audio.\n",
        "#     Args:\n",
        "#     - stft: STFT of the FOA audio with shape [4, Frequency Bins, Time Frames].\n",
        "#     - rho: Mean density of air (in kg/m^3).\n",
        "#     - c: Speed of sound in air (in m/s).\n",
        "\n",
        "#     Returns:\n",
        "#     - Ia: Active intensity vector.\n",
        "#     - Ir: Reactive intensity vector.\n",
        "#     \"\"\"\n",
        "#     # Constants\n",
        "#     three = torch.tensor(3.0, dtype=torch.float, device=stft.device)\n",
        "#     normalization_factor = -1 / (rho * c * torch.sqrt(three))\n",
        "\n",
        "#     # Extract channels\n",
        "#     p = stft[0]  # Pressure (W channel)\n",
        "#     vx = stft[1] * normalization_factor  # Velocity X\n",
        "#     vy = stft[2] * normalization_factor  # Velocity Y\n",
        "#     vz = stft[3] * normalization_factor  # Velocity Z\n",
        "\n",
        "#     # Compute complex conjugate of pressure\n",
        "#     p_star = torch.conj(p)\n",
        "\n",
        "#     # Calculate active and reactive intensity vectors\n",
        "#     Ia_x = torch.real(p_star * vx)\n",
        "#     Ia_y = torch.real(p_star * vy)\n",
        "#     Ia_z = torch.real(p_star * vz)\n",
        "\n",
        "#     Ir_x = torch.imag(p_star * vx)\n",
        "#     Ir_y = torch.imag(p_star * vy)\n",
        "#     Ir_z = torch.imag(p_star * vz)\n",
        "\n",
        "#     # Create stack for each channel [3, num_samples, num_frames]\n",
        "#     Ia = torch.stack((Ia_x, Ia_y, Ia_z), dim=0)\n",
        "#     Ir = torch.stack((Ir_x, Ir_y, Ir_z), dim=0)\n",
        "\n",
        "#     return Ia, Ir\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_active_reactive_intensities(stft, rho=1.21, c=343):\n",
        "    # Constants\n",
        "    normalization_factor = -1 / (rho * c * torch.sqrt(torch.tensor(3.0, dtype=torch.float, device=stft.device)))\n",
        "\n",
        "    # Extract channels\n",
        "    p = stft[0]  # Pressure (W channel)\n",
        "    vx = stft[1] * normalization_factor  # Velocity X\n",
        "    vy = stft[2] * normalization_factor  # Velocity Y\n",
        "    vz = stft[3] * normalization_factor  # Velocity Z\n",
        "\n",
        "    # Compute complex conjugate of pressure\n",
        "    p_star = torch.conj(p)\n",
        "\n",
        "    # Calculate active and reactive intensity vectors components\n",
        "    Ia_components = [torch.real(p_star * vx), torch.real(p_star * vy), torch.real(p_star * vz)]\n",
        "    Ir_components = [torch.imag(p_star * vx), torch.imag(p_star * vy), torch.imag(p_star * vz)]\n",
        "\n",
        "    # Calculate the total energy for normalization\n",
        "    e_p = torch.abs(p) ** 2\n",
        "    e_k = (torch.abs(vx) ** 2 + torch.abs(vy) ** 2 + torch.abs(vz) ** 2) / 3\n",
        "    e_T = e_p + e_k\n",
        "\n",
        "    # Create quaternion representations for active and reactive intensities\n",
        "    Ia_quat = torch.stack([torch.real(p_star * p)] + [torch.real(p_star * component) for component in [vx, vy, vz]], dim=0)\n",
        "    Ir_quat = torch.stack([torch.imag(p_star * p)] + [torch.imag(p_star * component) for component in [vx, vy, vz]], dim=0)\n",
        "\n",
        "    # Normalize the quaternion inputs\n",
        "    e_T = e_p + e_k  # Total energy\n",
        "    Ia_quat_normalized = Ia_quat / e_T\n",
        "    Ir_quat_normalized = Ir_quat / e_T\n",
        "\n",
        "    # Return the normalized quaternion intensities\n",
        "    return Ia_quat_normalized, Ir_quat_normalized\n"
      ],
      "metadata": {
        "id": "3op7wo592wCQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ApfOs6lkyB"
      },
      "source": [
        "## Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JNsmExR-IyMJ"
      },
      "outputs": [],
      "source": [
        "class AmbisonicDataset(Dataset):\n",
        "    def __init__(self, data, config):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (list of dicts): Each dictionary contains paths and labels for a sample.\n",
        "            config (dict): Configuration dictionary including sample rate (sr), duration, etc.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.config = config\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "\n",
        "        # Load and process ambisonic audio\n",
        "        speech_path = sample[\"speech_path\"]\n",
        "        noise_path = sample[\"noise_path\"] if \"noise_path\" in sample and sample[\"noise_path\"] is not None else None\n",
        "\n",
        "        stft_audio = load_mix_and_stft_foa_audio(\n",
        "            speech_path,\n",
        "            noise_pth=noise_path,\n",
        "            sr=self.config[\"sr\"],\n",
        "            duration=self.config[\"duration\"],\n",
        "            noise_ratio=self.config[\"noise_ratio\"],\n",
        "            n_fft=self.config[\"n_fft\"],\n",
        "            hop_length=self.config[\"hop_length\"],\n",
        "            win_length=self.config[\"win_length\"],\n",
        "            device=self.config[\"device\"]\n",
        "        )\n",
        "\n",
        "        # Compute active and reactive intensities\n",
        "        Ia, Ir = compute_active_reactive_intensities(stft_audio, rho=1.21, c=343)\n",
        "\n",
        "        # Generate Spike Trains\n",
        "        spikes_Ia = spikegen.rate(Ia, num_steps=self.config[\"num_steps\"])\n",
        "        spikes_Ir = spikegen.rate(Ir, num_steps=self.config[\"num_steps\"])\n",
        "\n",
        "        azimuth = sample['azimuth']\n",
        "        elevation = sample['elevation']\n",
        "        label = torch.tensor([azimuth, elevation], dtype=torch.float)\n",
        "\n",
        "        return spikes_Ia, spikes_Ir, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVfT-_QlkyB"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GNnMVrkNlU-6"
      },
      "outputs": [],
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(SNN, self).__init__()\n",
        "        self.num_steps = config[\"num_steps\"]\n",
        "        self.beta = config[\"beta\"]\n",
        "        self.beta_re = config[\"beta_re\"]\n",
        "        self.beta_out = config[\"beta_out\"]\n",
        "\n",
        "        # Active Thresholds\n",
        "        self.a_thr1 = config[\"a_thresh1\"]\n",
        "        self.a_thr2 = config[\"a_thresh2\"]\n",
        "        self.a_thr3 = config[\"a_thresh3\"]\n",
        "        self.a_thr4 = config[\"a_thresh4\"]\n",
        "\n",
        "        # Reactive Thresholds\n",
        "        self.re_thr1 = config[\"re_thresh1\"]\n",
        "        self.re_thr2 = config[\"re_thresh2\"]\n",
        "        self.re_thr3 = config[\"re_thresh3\"]\n",
        "        self.re_thr4 = config[\"re_thresh4\"]\n",
        "\n",
        "        ## FC Layer\n",
        "        self.beta_out = config[\"beta_out\"]\n",
        "        self.out_thr1 = config[\"out_thresh1\"]\n",
        "        self.out_thr2 = config[\"out_thresh2\"]\n",
        "        self.do = config[\"do\"]\n",
        "\n",
        "        # Define the active branch with LIF neurons\n",
        "        self.active_branch = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=3),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta, threshold=self.a_thr1, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta, threshold=self.a_thr2, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta, threshold=self.a_thr3, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta, threshold=self.a_thr4, init_hidden=True),\n",
        "        )\n",
        "\n",
        "        self.reactive_branch = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=3),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta_re, threshold=self.re_thr1, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta_re, threshold=self.re_thr2, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta_re, threshold=self.re_thr3, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "            snn.Leaky(beta=self.beta_re, threshold=self.re_thr4, init_hidden=True),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(7680, 512),\n",
        "            snn.Leaky(beta=self.beta_out, threshold=self.out_thr1, init_hidden=True),\n",
        "            nn.Linear(512, 256),\n",
        "            snn.Leaky(beta=self.beta_out, threshold=self.out_thr2, init_hidden=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.Dropout(p=self.do),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    # def forward(self, active_input, reactive_input):\n",
        "    #     active_in_permuted = active_input.permute(1, 0, 2, 3, 4) # [num_step, batch_size, channels, num_samples, num_frames]\n",
        "    #     reactive_in_permuted = reactive_input.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "    #     active_outputs = []\n",
        "    #     reactive_outputs = []\n",
        "\n",
        "    #     for step in range(active_in_permuted.size(0)):\n",
        "    #         active_step = self.active_branch(active_in_permuted[step])\n",
        "    #         reactive_step = self.reactive_branch(reactive_in_permuted[step])\n",
        "\n",
        "    #         active_outputs.append(active_step)\n",
        "    #         reactive_outputs.append(reactive_step)\n",
        "\n",
        "    #     # Stack the outputs across time steps to form tensors of shape [num_steps, batch_size, channels, height, width]\n",
        "    #     active_stacked = torch.stack(active_outputs, dim=0)\n",
        "    #     reactive_stacked = torch.stack(reactive_outputs, dim=0)\n",
        "\n",
        "    #     # Aggregate across time steps, e.g., by taking the mean or sum\n",
        "    #     active_agg = torch.mean(active_stacked, dim=0)\n",
        "    #     reactive_agg = torch.mean(reactive_stacked, dim=0)\n",
        "\n",
        "    #     # Flatten and concatenate the aggregated outputs for the final MLP\n",
        "    #     active_flat = active_agg.view(active_agg.size(0), -1)\n",
        "    #     reactive_flat = reactive_agg.view(reactive_agg.size(0), -1)\n",
        "    #     combined = torch.cat((active_flat, reactive_flat), dim=1)\n",
        "\n",
        "    #     output = self.fc(combined)\n",
        "\n",
        "    #     return output\n",
        "\n",
        "    def forward(self, active_input, reactive_input):\n",
        "        step_outputs = []\n",
        "        permute_active = active_input.permute(1, 0, 2, 3, 4)\n",
        "        permute_reactive = reactive_input.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        if permute_active.size(0) != permute_reactive.size(0):\n",
        "            raise ValueError(\"The Tme Steps from active and reactive Do NOT Match\")\n",
        "\n",
        "        for step in range(permute_active.size(0)):\n",
        "\n",
        "            current_active = permute_active[step]\n",
        "            current_reactive = permute_reactive[step]\n",
        "\n",
        "            # Process inputs through active and reactive branches\n",
        "            active_out = self.active_branch(current_active)\n",
        "            reactive_out = self.reactive_branch(current_reactive)\n",
        "\n",
        "            # Flatten and combine the outputs\n",
        "            combined = torch.cat((active_out, reactive_out), dim=1)\n",
        "            combined = combined.view(combined.size(0), -1)\n",
        "\n",
        "            fc_out = self.fc(combined)\n",
        "\n",
        "            step_outputs.append(fc_out)\n",
        "            # print(f\"current_active.shape: {current_active.shape}, current_reactive.shape: {current_reactive.shape}\")\n",
        "            # print(f\"active_out.shape: {active_out.shape}, reactive_out.shape: {reactive_out.shape}\")\n",
        "            # print(f\"combined.shape: {combined.shape}\")\n",
        "            # print(f\"fc_out.shape: {fc_out.shape}\")\n",
        "\n",
        "        tensor_out = torch.stack(step_outputs, dim=0)\n",
        "        output = torch.mean(tensor_out, dim=0)\n",
        "        # print(f\"tensor_out.shape: {tensor_out.shape}\")\n",
        "        # print(f\"output.shape: {output.shape}, output: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQdTxNRSlkyC"
      },
      "source": [
        "## Util Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jjquDUYFhDmf"
      },
      "outputs": [],
      "source": [
        "def calc_median_absolute_error(t_azimuth, t_elevation, p_azimuth, p_elevation):\n",
        "    \"\"\"\n",
        "    Calculate the median absolute error of the angular distance between the true\n",
        "    and predicted azimuth and elevation angles.\n",
        "\n",
        "    Parameters:\n",
        "    t_azimuth (tensor): Azimuth angles of the true points in radians.\n",
        "    t_elevation (tensor): Elevation angles of the true points in radians.\n",
        "    p_azimuth (tensor): Azimuth angles of the predicted points in radians.\n",
        "    p_elevation (tensor): Elevation angles of the predicted points in radians.\n",
        "\n",
        "    Returns:\n",
        "    tensor: The median angular distance in degrees.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the cosine of the angular distance\n",
        "    cosine_of_angle = (\n",
        "        torch.sin(t_azimuth) * torch.sin(p_azimuth) +\n",
        "        torch.cos(t_azimuth) * torch.cos(p_azimuth) * torch.cos(t_elevation - p_elevation)\n",
        "    )\n",
        "\n",
        "    # Clamp the cosine of the angle to the range [-1, 1] to avoid errors due to numerical instability\n",
        "    cosine_of_angle = torch.clamp(cosine_of_angle, -1, 1)\n",
        "\n",
        "    # Calculate the angular distance in radians\n",
        "    error_rad = torch.acos(cosine_of_angle)\n",
        "\n",
        "    # Convert the angular distance from radians to degrees\n",
        "    error_deg = torch.rad2deg(error_rad)\n",
        "\n",
        "    # Calculate the median of the absolute errors in degrees\n",
        "    median_error = torch.median(torch.abs(error_deg))\n",
        "\n",
        "    return median_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZFel4tlkyC"
      },
      "source": [
        "## Training, Validation and Testing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0_Dg3yllkyC"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-UHrSaeJgv_X"
      },
      "outputs": [],
      "source": [
        "# def train(model, train_loader, criterion, optimizer, device):\n",
        "#     model.train()  # Set model to training mode\n",
        "\n",
        "#     train_loss = 0.0\n",
        "#     true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "#     for batch_idx, (active_input, reactive_input, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "#         #print(f\"Batch {batch_idx+1}/{len(train_loader)}\")\n",
        "\n",
        "#         # Move data and labels to the device\n",
        "#         active_input, reactive_input, labels = active_input.to(device), reactive_input.to(device), labels.to(device)\n",
        "\n",
        "#         # Reset branches - required for init_hidden=True\n",
        "#         utils.reset(model.active_branch)\n",
        "#         utils.reset(model.reactive_branch)\n",
        "\n",
        "#         # Zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Forward pass\n",
        "#         outputs = model(active_input, reactive_input)  # Pass both inputs to the model\n",
        "\n",
        "#         # Compute loss\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         # Backward pass and optimize\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Update training loss\n",
        "#         train_loss = train_loss + loss.item() * active_input.size(0)\n",
        "\n",
        "#         true_azimuths.append(labels[:, 0].detach())\n",
        "#         true_elevations.append(labels[:, 1].detach())\n",
        "#         pred_azimuths.append(outputs[:, 0].detach())\n",
        "#         pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "#     # Calculate average loss over the dataset\n",
        "#     train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "#     return train_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6g4TB5AjlkyD"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    train_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    for batch_idx, (active_input, reactive_input, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        # Move data and labels to the device\n",
        "        active_input, reactive_input, labels = active_input.to(device), reactive_input.to(device), labels.to(device)\n",
        "\n",
        "        # Check if model is wrapped in DataParallel and access the original model for reset\n",
        "        if isinstance(model, nn.DataParallel):\n",
        "            utils.reset(model.module.active_branch)\n",
        "            utils.reset(model.module.reactive_branch)\n",
        "        else:\n",
        "            utils.reset(model.active_branch)\n",
        "            utils.reset(model.reactive_branch)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(active_input, reactive_input)  # Pass both inputs to the model\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update training loss\n",
        "        train_loss += loss.item() * active_input.size(0)\n",
        "\n",
        "        true_azimuths.append(labels[:, 0].detach())\n",
        "        true_elevations.append(labels[:, 1].detach())\n",
        "        pred_azimuths.append(outputs[:, 0].detach())\n",
        "        pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    # Calculate average loss over the dataset\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVB8zFH7lkyD"
      },
      "source": [
        "### Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a3KVmEoEgyc8"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed\n",
        "        for batch_idx, (active_input, reactive_input, labels) in enumerate(tqdm(val_loader, desc=\"Validation\")):\n",
        "            #print(f\"Batch {batch_idx+1}/{len(val_loader)}\")\n",
        "\n",
        "            # Move the inputs and labels to the specified device\n",
        "            active_input, reactive_input, labels = active_input.to(device), reactive_input.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass: compute the model output\n",
        "            outputs = model(active_input, reactive_input)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss = valid_loss + loss.item() * active_input.size(0)\n",
        "\n",
        "            true_azimuths.append(labels[:, 0].detach())\n",
        "            true_elevations.append(labels[:, 1].detach())\n",
        "            pred_azimuths.append(outputs[:, 0].detach())\n",
        "            pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    # Calculate the average loss over the dataset\n",
        "    valid_loss = valid_loss / len(val_loader.dataset)\n",
        "\n",
        "    return valid_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxe4xc-lkyD"
      },
      "source": [
        "### Testing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4xUJ05NBg27K"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    test_loss = 0.0\n",
        "    true_azimuths, true_elevations, pred_azimuths, pred_elevations = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed during testing\n",
        "        for batch_idx, (active_input, reactive_input, labels) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
        "            active_input, reactive_input, labels = active_input.to(device), reactive_input.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass: compute the model output\n",
        "            outputs = model(active_input, reactive_input)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss = test_loss + loss.item() * active_input.size(0)\n",
        "\n",
        "            # Optionally, accumulate metrics here\n",
        "            true_azimuths.append(labels[:, 0].detach())\n",
        "            true_elevations.append(labels[:, 1].detach())\n",
        "            pred_azimuths.append(outputs[:, 0].detach())\n",
        "            pred_elevations.append(outputs[:, 1].detach())\n",
        "\n",
        "    # Calculate the average loss over the dataset\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, torch.cat(true_azimuths), torch.cat(true_elevations), torch.cat(pred_azimuths), torch.cat(pred_elevations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDHYL_OjlkyD"
      },
      "source": [
        "## DataLoaders, Training setup, Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8oLPwU-lkyD"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1j_wWBIwg96V"
      },
      "outputs": [],
      "source": [
        "data = filter_data()\n",
        "train_data, val_data, test_data = split_data(data)\n",
        "\n",
        "train_dataset = AmbisonicDataset(data=train_data, config=config)\n",
        "val_dataset = AmbisonicDataset(data=val_data, config=config)\n",
        "test_dataset = AmbisonicDataset(data=test_data, config=config)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xuaq9JflkyE"
      },
      "source": [
        "### Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tvCPyyKuhBhi"
      },
      "outputs": [],
      "source": [
        "device = config[\"device\"]\n",
        "\n",
        "model = SNN(config)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n",
        "    model = torch.nn.DataParallel(model)\n",
        "model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj2fMDbPlkyE"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNpbk7KRh_BP"
      },
      "outputs": [],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
        "\n",
        "    train_epoch_loss, train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation = train(model, train_loader, criterion, optimizer, device)\n",
        "    valid_epoch_loss, valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "\n",
        "    train_angle_error = calc_median_absolute_error(train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation)\n",
        "    valid_angle_error = calc_median_absolute_error(valid_true_azimuth, valid_true_elevation, valid_pred_azimuth, valid_pred_elevation)\n",
        "\n",
        "    print(f\"Train Loss: {train_epoch_loss:.4f} | Validation Loss: {valid_epoch_loss:.4f}\")\n",
        "    print(f\"Train Angle Error: {train_angle_error:.4f}° | Validation Angle Error: {valid_angle_error:.4f}°\\n\")\n",
        "\n",
        "test_loss, test_true_azimuth, test_true_elevation, test_pred_azimuth, test_pred_elevation = test(model, test_loader, criterion, device)\n",
        "test_angle_error = calc_median_absolute_error(test_true_azimuth, test_true_elevation, test_pred_azimuth, test_pred_elevation)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Angle Error: {test_angle_error:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AMT38KClkyE"
      },
      "source": [
        "## Hypyerparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIgajG9lkyE"
      },
      "source": [
        "### Objective Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUbG7PSIQBSV"
      },
      "outputs": [],
      "source": [
        "# def objective(trial):\n",
        "#     # Hyperparameters to optimize\n",
        "#     config[\"a_thresh1\"] = trial.suggest_float(\"a_thresh1\", 2, 5)\n",
        "#     config[\"a_thresh2\"] = trial.suggest_float(\"a_thresh2\", 7, 10)\n",
        "#     config[\"a_thresh3\"] = trial.suggest_float(\"a_thresh3\", 11, 14)\n",
        "#     config[\"a_thresh4\"] = trial.suggest_float(\"a_thresh4\", 15, 19)\n",
        "#     config[\"beta\"] = trial.suggest_float(\"beta\", 0.1, 0.4)\n",
        "\n",
        "\n",
        "#     config[\"re_thresh1\"] = trial.suggest_float(\"re_thresh1\", 19, 23)\n",
        "#     config[\"re_thresh2\"] = trial.suggest_float(\"re_thresh2\", 17, 21)\n",
        "#     config[\"re_thresh3\"] = trial.suggest_float(\"re_thresh3\", 25, 30)\n",
        "#     config[\"re_thresh4\"] = trial.suggest_float(\"re_thresh4\", 17, 21)\n",
        "#     config[\"beta_re\"] = trial.suggest_float(\"beta_re\", 0.5, 0.7)\n",
        "\n",
        "#     config[\"out_thresh1\"] = trial.suggest_float(\"out_thresh1\", 2, 6)\n",
        "#     config[\"out_thresh2\"] = trial.suggest_float(\"out_thresh2\", 7, 11)\n",
        "#     config[\"beta_out\"] = trial.suggest_float(\"beta_out\", 0.4, 0.6)\n",
        "\n",
        "#     config[\"do\"] = trial.suggest_float(\"do\", 0.6, 0.9)\n",
        "#     config[\"num_steps\"] = trial.suggest_int(\"num_steps\", 15, 25)\n",
        "#     config[\"lr\"] = trial.suggest_float(\"lr\", 1e-8, 1e-4)\n",
        "\n",
        "\n",
        "\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model = SNN(config)\n",
        "#     if torch.cuda.device_count() > 1:\n",
        "#         print(f\"Using {torch.cuda.device_count()} GPUs.\")\n",
        "#         model = nn.DataParallel(model)\n",
        "\n",
        "#     model.to(device)\n",
        "#     criterion = nn.MSELoss()\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "#     data = filter_data()\n",
        "#     train_data, _, _ = split_data(data)\n",
        "\n",
        "#     train_dataset = AmbisonicDataset(data=train_data, config=config)\n",
        "\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n",
        "\n",
        "#     for epoch in range(config[\"num_epochs\"]):\n",
        "#         train_loss, train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation = train(model, train_loader, criterion, optimizer, device)\n",
        "#         train_angle_error = calc_median_absolute_error(train_true_azimuth, train_true_elevation, train_pred_azimuth, train_pred_elevation)\n",
        "\n",
        "\n",
        "#     return train_angle_error.item()  # Optuna minimizes this value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IjxfwElkyE"
      },
      "source": [
        "### Run Study Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT8BYIRQQODD"
      },
      "outputs": [],
      "source": [
        "# def run_study():\n",
        "#     study_name = \"snn_study\"\n",
        "#     storage_name = \"sqlite:///{}.db\".format(study_name)\n",
        "\n",
        "#     study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True, direction=\"minimize\")\n",
        "#     study.optimize(objective, n_trials=5)\n",
        "\n",
        "#     # Save the study to disk\n",
        "#     study.trials_dataframe().to_csv(\"study_results.csv\")\n",
        "\n",
        "#     print(\"Study statistics: \")\n",
        "#     print(\"  Number of finished trials: \", len(study.trials))\n",
        "#     print(\"  Best trial:\")\n",
        "#     trial = study.best_trial\n",
        "#     print(\"    Value: \", trial.value)\n",
        "#     print(\"    Params: \")\n",
        "#     for key, value in trial.params.items():\n",
        "#         print(f\"      {key}: {value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aTJaM96QRGA"
      },
      "outputs": [],
      "source": [
        "# run_study()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}